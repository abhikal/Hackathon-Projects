{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"HHc4hn2bUEco","colab_type":"code","outputId":"974a944b-2e6c-4cd0-ca86-24c5a691e5ea","colab":{"base_uri":"https://localhost:8080/","height":105},"trusted":true},"cell_type":"code","source":"pip install fuzzywuzzy","execution_count":null,"outputs":[]},{"metadata":{"id":"fQqqS__ljOuq","colab_type":"code","outputId":"0fd44262-3266-4621-96a9-8f9599c03711","colab":{"base_uri":"https://localhost:8080/","height":122},"trusted":true},"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"34HWyzcGjqpV","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# from google.colab import files\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"POjDy7jbxQqv","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#import important libraries\nfrom fuzzywuzzy import process\nimport re","execution_count":null,"outputs":[]},{"metadata":{"id":"VhtkA45ajcHz","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"path = \"../input/\"\n\n# customer_df = pd.read_csv(path + 'customer.csv')\n# invoice_df = pd.read_csv(path + 'invoice.csv')\n# jtd_df = pd.read_csv(path + 'jtd.csv')\n# plant_df = pd.read_csv(path + 'plant.csv')\n# vehicles_df = pd.read_csv(path + 'vehicles.csv')\n\ncustomer_df = pd.read_csv(path + 'customer.csv')\ninvoice_df = pd.read_csv(path + 'invoice.csv')\njtd_df = pd.read_csv(path + 'jtd.csv')\nplant_df = pd.read_csv(path + 'plant.csv')\nvehicles_df = pd.read_csv(path + 'vehicles.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" invoice_df shape : \",invoice_df.shape)\nprint(\" customer_df shape: \",customer_df.shape)\nprint(\" plant_df shape   : \",plant_df.shape)\nprint(\" vehicles_df shape: \",vehicles_df.shape)\nprint(\" jtd_df shape     : \",jtd_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"w2zIxRzAkpQb","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# 1. drop unwanted columns from all dataframes\ndef drop_col(dataset, col_to_drop):\n    dataset.drop(col_to_drop, axis=1, inplace=True)\n    return dataset\n\n# 2. lowercase all the categorical columns\ndef lowercase(dataset):\n    categorical_col = dataset.select_dtypes(exclude=['number']).columns\n    for col in categorical_col:\n        dataset[col] = dataset[col].map(lambda x: x if type(x)!=str else x.lower())\n    return dataset\n\ninvoice_columns_to_drop  = ['Unnamed: 0', 'Amt Rcvd From Custom', 'Amt Rcvd From Ins Co','Area / Locality',\n                            'CGST(14%)', 'CGST(2.5%)', 'CGST(6%)', 'CGST(9%)',\n                            'IGST(12%)', 'IGST(18%)', 'IGST(28%)', 'IGST(5%)', 'Insurance Company',\n                            'Outstanding Amt', 'SGST/UGST(14%)', 'SGST/UGST(2.5%)', 'SGST/UGST(6%)', 'SGST/UGST(9%)',\n                            'Service Advisor Name', 'TDS amount', 'Total CGST', 'Total GST', 'Total IGST',\n                            'Total SGST/UGST','Plant Name1','Recovrbl Exp']\ncustomer_columns_to_drop = ['Unnamed: 0','Death date']\nplant_columns_to_drop    = ['Unnamed: 0','Name 1','Factory calendar','Valuation Area',\n                           'Customer no. - plant','PO Box','Postal Code','Name 2',\n                           'Vendor number plant','House number and street']\njtd_columns_to_drop      = ['Unnamed: 0']\nvehicles_columns_to_drop = ['Unnamed: 0','Product GUID']\n\ndataframes = [invoice_df, customer_df, plant_df, jtd_df, vehicles_df]\ndataframe_columns_to_drop = [invoice_columns_to_drop, customer_columns_to_drop, plant_columns_to_drop,\n                             jtd_columns_to_drop, vehicles_columns_to_drop]\n\nfor i in range(len(dataframes)):\n    dataframes[i] = drop_col(dataframes[i],dataframe_columns_to_drop[i])\n    dataframes[i] = lowercase(dataframes[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"sVeGROVWuCIU","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\n# Preprocessing for dataset merge operation\n\n# 1. Remove leading zeros from 'Customer No.' column\ndef remove_leading_zeros(dataset,cols):\n    for col in cols:\n          dataset[col] = dataset[col].astype(str).apply(lambda x: x.lstrip(\"0\"))\n    return dataset\ninvoice_df  = remove_leading_zeros(invoice_df,['Customer No.'])\ncustomer_df = remove_leading_zeros(customer_df,['Customer No.'])\n\n\n# 2. Rename columns to use them as key column for merge operation\ndef rename_columns(dataset, rename_cols_dict):\n    dataset.rename(columns=rename_cols_dict, inplace=True)\n    return dataset\ndict_invoice_df = {'District':'State'}\ndict_vehicles_df = {'Vehicle Model':'Make', 'License Plate Number':'Regn No'}\n\ninvoice_df  = rename_columns(invoice_df, dict_invoice_df)\nvehicles_df = rename_columns(vehicles_df, dict_vehicles_df)\n\n\n# 3. Replace values in key columns for merge operation\ndef replacement(dataset, col, dict_replacement, regex=False):\n    dataset[col] = dataset[col].replace(dict_replacement, regex=regex )\n    return dataset\nmake_replacements = {\n                    'mahindra &  mahindra': 'mahindra',\n                    'tata motors': 'tata',\n                    'maruti suzuki': 'maruti',\n                    'mercedes benz': 'mercedes-benz',\n                    'porche': 'porsche',\n                    'land rover' : 'rover',\n                    'mitsubishi motors':'mitsubishi motor',\n                    'premier\\xa0automobiles': 'premierauto'\n                    }\npattern_replacement = {'z_':''}\nvehicles_df = replacement(vehicles_df, 'Make', pattern_replacement, regex=True)\nvehicles_df = replacement(vehicles_df, 'Make', make_replacements)\ninvoice_df  = replacement(invoice_df, 'Make', make_replacements)\n\n# 4. Drop rows where license plate number is less than 1 \nmask = (vehicles_df['Regn No'].str.len() > 1)\nvehicles_df = vehicles_df.loc[mask]","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"Bwnf_Q2LvmGg","colab":{},"trusted":true},"cell_type":"code","source":"# Merge dataframes based on key\ndef merge_df(left_df, right_df, key):\n    merge_df = pd.merge(left=left_df, right=right_df, how='left', on=key)\n    return merge_df\n\ninvoice_customer_df = merge_df(left_df=invoice_df, right_df=customer_df,key=['Customer No.'])\ninvoice_customer_plant_df = merge_df(left_df=invoice_customer_df, right_df=plant_df,key=['Plant','State'])\ninvoice_customer_plant_vehicles_df = merge_df(left_df=invoice_customer_plant_df, right_df=vehicles_df,key=['Regn No','Make'])\n\nmaster_df = invoice_customer_plant_vehicles_df","execution_count":null,"outputs":[]},{"metadata":{"id":"01UPBWu0KzgE","colab_type":"code","outputId":"1ff83db8-5255-481a-e21b-676ecf34fa1a","colab":{"base_uri":"https://localhost:8080/","height":136},"trusted":true},"cell_type":"code","source":"print(\" invoice_df : \",invoice_df.shape)\nprint(\" customer_df : \",customer_df.shape)\nprint(\" invoice_customer_df : \",invoice_customer_df.shape)\nprint(\" plant_df : \",plant_df.shape)\nprint(\" invoice_customer_plant_df : \",invoice_customer_plant_df.shape)\nprint(\" vehicles_df : \",vehicles_df.shape)\nprint(\" invoice_customer_plant_vehicles_df  : \",invoice_customer_plant_vehicles_df.shape)\nprint(\" master_df : \",master_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"zvVmBjhz9bwN","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# create column 'Regn State' from 'Regn No'\nurl = 'https://kb.bullseyelocations.com/support/solutions/articles/5000695302-india-state-codes'\nfile = pd.read_html(url, header=0)\n\n# 1. get the state abbrevation from site\nstates_df = file[0]\nstates_df.drop(['Alternate Abbreviation'], axis=1, inplace=True)\nstates_df['Abbreviation'] = states_df['Abbreviation'].str.lower()\n\n# 2. Create abbrevation from Regn No\nmaster_df['Abbreviation'] = master_df['Regn No'].astype(str).str[:2]\nmaster_df = master_df[master_df['Abbreviation'].str.isalpha()]\n\n# 3. merge dataframes to get the State Name \nmaster_df = merge_df(left_df=master_df, right_df=states_df,key=['Abbreviation'])\n\n# rename State column\nmaster_df = rename_columns(master_df, {'State Name':'Regn State'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df[['Regn No', 'Regn State']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"id":"3ebfqCjDyxUT","colab_type":"code","outputId":"e3d43aa9-9bd5-40ce-f528-4f4ac712d034","colab":{"base_uri":"https://localhost:8080/","height":510},"trusted":true},"cell_type":"code","source":"# fill missing values for City\nmaster_df['City'] = master_df['City'].fillna(master_df['CITY'])\nmaster_df = drop_col(master_df,'CITY')\n\n# Function to identify the number of missing values in every feature\ndef missing_datas(dataset):\n    total = dataset.isnull().sum().sort_values(ascending=False)\n    percent = ((dataset.isnull().sum())*100/dataset.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\n    \nmissing_data_master_df = missing_datas(master_df)\nprint(\"missing data for 'master_df': \")\nprint(missing_data_master_df[missing_data_master_df['Percent']>0.00])\n\nmissing_data_jtd_df = missing_datas(jtd_df)\nprint(\"missing data for 'jtd_df': \")\nprint(missing_data_jtd_df[missing_data_jtd_df['Percent']>0.00])","execution_count":null,"outputs":[]},{"metadata":{"id":"-3XDnJTC0zmt","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Function to drop missing values\ndef drop_missing(dataset, missing, min_threshold, max_threshold):\n    dataset = dataset.drop((missing[missing['Percent'] > max_threshold]).index,axis= 1)\n    dataset = dataset.dropna(axis=0, subset=(missing[missing['Percent'] < min_threshold]).index)\n    return dataset \n\nmaster_df  = drop_missing(master_df,missing_data_master_df,2,40)\njtd_df     = drop_missing(jtd_df,missing_data_jtd_df,2,40)","execution_count":null,"outputs":[]},{"metadata":{"id":"kPjHYn-Qb1X1","colab_type":"code","outputId":"5e3e18dd-f050-4843-e8c1-b43a63b89e7a","colab":{"base_uri":"https://localhost:8080/","height":153},"trusted":true},"cell_type":"code","source":"#recheck the missing values\nnew_missing_data = missing_datas(master_df)\nprint(\"missing data for 'master_df'\")\nprint(new_missing_data[new_missing_data['Percent']>0.00])\n\nnew_missing_data = missing_datas(jtd_df)\nprint(\"missing data for 'jtd_df'\")\nprint(new_missing_data[new_missing_data['Percent']>0.00])","execution_count":null,"outputs":[]},{"metadata":{"id":"dWLLSDnKNpiS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#fill missing values with mode\ndef Fill_Missing_Values(dataset, cols):\n    for col in cols:\n        dataset[col].fillna(dataset[col].dropna().mode()[0], inplace = True)\n    return dataset\n  \nmaster_df = Fill_Missing_Values(dataset=master_df,cols=['Sales organization','Title','Regn State'])","execution_count":null,"outputs":[]},{"metadata":{"id":"PqzSDGdOoxx0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# combine Date & Time columns\ndef to_datetime(dataset, datetime_cols):\n    for datetime in datetime_cols:\n        dataset[datetime[0] + '-' + datetime[1]] = pd.to_datetime(dataset[datetime[0]]+ ' ' + dataset[datetime[1]])\n    return dataset\ndatetime_cols = ['Invoice Date','Invoice Time','JobCard Date','JobCard Time']\nmaster_df = to_datetime(master_df, [['Invoice Date','Invoice Time'],['JobCard Date','JobCard Time']])\n\n\n#split datetime column\nmaster_df['Year']  = master_df['Invoice Date-Invoice Time'].dt.year\nmaster_df['Month'] = master_df['Invoice Date-Invoice Time'].dt.month\n\n\n# add job duration column\ndef job_completion_time(dataset, start_datetime, end_datetime):\n    dataset['Job_duration(in days)'] = (dataset[start_datetime] - dataset[end_datetime]) / np.timedelta64(1,'D')\n    return dataset\nmaster_df = job_completion_time(master_df, 'Invoice Date-Invoice Time', 'JobCard Date-JobCard Time')\n\n\n# add total all costs to get 'Total Expenses'\ndef sum_cols(dataset, cols_to_sum, result_col):\n    dataset[result_col] = 0\n    for col in cols_to_sum:\n        dataset[result_col] = dataset[result_col] + dataset[col]\n    return dataset\ncost_cols     = ['Misc Total','OSL Total','Parts Total','Total Amt Wtd Tax.']\nmaster_df =  sum_cols(master_df, cost_cols, 'Total_Expense')\n\n\n#remove dulicate column Date-Time columns\nmaster_df = drop_col(master_df, datetime_cols)\nmaster_df = drop_col(master_df, cost_cols)\n\n# drop unique value columns\nunique_cols = ['User ID','Regn No','Pin code','Invoice No','Job Card No','Abbreviation']\nmaster_df = drop_col(master_df, unique_cols)","execution_count":null,"outputs":[]},{"metadata":{"id":"X8dlXs5-Ttvg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# map column description\ndef map_description(dataset,col, map_dict):\n    dataset[col] = dataset[col].astype(str).map(map_dict)\n    return dataset\n\ndata_origin_dict = { 'z001':'Camp-Outdoor','z002':'Camp-Workshop','z003':'Emailers',\n                     'z004':'Fleet','z005':'Ref-Customer','z006':'Ref-Employee',\n                     'z007':'Used Car Dealer','z008':'Just Dial/Other',\n                     'z009':'Snapdeal/Web','z010':'Company website',\n                     'z011':'Float activity','z012':'Petrol pump',\n                     'z013':'Hoardings/ADVT','z014':'Insurance Co',\n                     'z015':'Television AD','z016':'Newspaper AD',\n                     'z017':'Newsppr leaflet','z018':'Sales Activity',\n                     'z019':'Spotted outlet','z020':'M & M Employee',\n                     'z021':'Outdoor Activty','z022':'Radio'\n                  }\n\npartner_type_dict = {'1.0':'Retail','2.0':'Corporate','3.0':'Fleet',\n                     '4.0':'Employee','9001.0':'Insurance Company',\n                     '9002.0':'Surveyor','9003.0':'Contact Person'\n                    }\n\nmaster_df = map_description(master_df,'Data Origin', data_origin_dict)\nmaster_df = map_description(master_df,'Partner Type', partner_type_dict)\n\n# change columns dtype\n\ndef modify_col_type(dataset, col, dtype):\n    dataset[col] = dataset[col].astype(dtype)\n    return dataset\n\nmaster_df = modify_col_type(master_df, 'Fuel Type', int)","execution_count":null,"outputs":[]},{"metadata":{"id":"Irj6rlFfjsto","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"e6127d48-f78b-4860-c22c-b80858ee74d2","trusted":true},"cell_type":"code","source":"# Function to identify numeric features\ndef numeric_features(dataset):\n    numeric_col = dataset.select_dtypes(include=['number']).columns\n    return numeric_col\n\nnumeric_columns_master_df = numeric_features(master_df)\nprint(\"Numeric Features for master_df:\")\nprint(numeric_columns_master_df)\n\nnumeric_columns_jtd_df = numeric_features(jtd_df)\nprint(\"Numeric Features for jtd_df:\")\nprint(numeric_columns_jtd_df)\n\nprint(\"====\"*30)\n\n# Function to identify categorical features\ndef categorical_features(dataset):\n    categorical_col = dataset.select_dtypes(exclude=['number']).columns\n    return categorical_col\n\ncategorical_columns_master_df = categorical_features(master_df)\nprint(\"Categorical Features for master_df:\")\nprint(categorical_columns_master_df)\n\ncategorical_columns_jtd_df = categorical_features(jtd_df)\nprint(\"categorical Features for jtd_df:\")\nprint(categorical_columns_jtd_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZdfF0dCjX2ne","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def display_unique_values(dataset, categirical_cols, info='count'):\n    print(\"Unique values: \")  \n    for col in categirical_cols:\n        if(info == 'values'):\n                print(\"{} : {}\".format(col, dataset[col].unique()))\n        elif(info == 'count'):\n                print(\"{} : {}\".format(col, len(dataset[col].unique())))\n    return None\n\ndisplay_unique_values(master_df, categorical_columns_master_df, 'count')   \ndisplay_unique_values(master_df, categorical_columns_master_df, 'values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Some Common Functions**"},{"metadata":{"id":"y9jtMHPoJ6mO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":457},"outputId":"47bde0e3-731c-4822-94c1-42629f49a30f","trusted":true},"cell_type":"code","source":"def get_top_values(dataset,col,min_percentage):\n    filtered_df = dataset[col].value_counts()\n    filtered_df=filtered_df.reset_index()\n    filtered_df[col] = (filtered_df[col]/sum(filtered_df[col]))*100\n    filtered_df = filtered_df.sort_values(col)\n    filtered_df = filtered_df[filtered_df[col]>min_percentage]\n    top_values  = filtered_df['index'].tolist()\n    top_values_df = dataset[dataset[col].isin(top_values)]\n    return top_values_df, top_values\n\ndef plot_TimeSeries(dataset, time_col, cat_col, num_col):\n    fig, ax = plt.subplots(figsize=(15,7))\n    plt.title(\"'{}'wise '{}' in top '{}'\".format(time_col, num_col, cat_col))\n    dataset.groupby([time_col,cat_col])[num_col].sum().unstack().plot(ax=ax,marker='o')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **Problem Statement-** : \nIdentifying the ownership pattern of cars throughout the\ncountry. \nThis also captures the problem wherein information regarding the\nspending patterns can be identified."},{"metadata":{},"cell_type":"markdown","source":"**Univariate Analysis**"},{"metadata":{"id":"xUhyAM7vGK7o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":293},"outputId":"1c888ec2-34cf-41c8-aa44-cc72e9454fff","trusted":true},"cell_type":"code","source":"def count_plot(dataset,col,min_threshold=0.7, title=None):\n        filtered_df = dataset[col].value_counts()\n        filtered_df=filtered_df.reset_index()\n        filtered_df[col] = (filtered_df[col]/sum(filtered_df[col]))*100\n        filtered_df = filtered_df.sort_values(col)\n        filtered_df = filtered_df[filtered_df[col]>min_threshold]\n#         fig, ax = plt.subplots(figsize=(10,8))\n        plt.bar(filtered_df['index'],filtered_df[col])\n        plt.style.use('fivethirtyeight')\n        if(title==None):\n            plt.title('Count plot for \"{}\"'.format(col))\n        plt.ylabel('Percentage')\n        plt.xlabel(col)\n        plt.xticks(rotation='vertical')\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot(master_df,'Fuel Type',0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot(master_df,'Regn State')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot(master_df,'Make')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot(master_df,'Order Type')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bivariate Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_hue_plot(dataset,x_col, hue_col, min_percentage,title=None):\n    sns.set(style=\"darkgrid\")\n    fig, ax = plt.subplots(figsize=(20, 10))\n    filtered_df1, filter_col_values1 = get_top_values(master_df, x_col, min_percentage)\n    filtered_df, filter_col_values = get_top_values(filtered_df1, hue_col, min_percentage)\n    sns.countplot(x=x_col, data=filtered_df, hue=hue_col)\n    if(title==None):\n        plt.title(\"'{}' wise distribution for '{}'\".format(x_col,hue_col))\n    plt.xticks(rotation='vertical')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_hue_plot(master_df,'State','Order Type', 1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_hue_plot(master_df,'State','Make', 1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_hue_plot(master_df,'State','Fuel Type', 0.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_hue_plot(master_df,'Make','Fuel Type', 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_state_df, top_state = get_top_values(master_df, 'State',1)\nplot_TimeSeries(top_state_df,'Year','State','Total_Expense')","execution_count":null,"outputs":[]},{"metadata":{"id":"l5wqg3wzc7Ev","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":376},"outputId":"904f014b-6a3b-4bbd-f4ff-22c9c068ca4a","trusted":true},"cell_type":"code","source":"def scatter_plot(df,x,y):\n    plt.style.use('seaborn')\n    plt.scatter(df[x],df[y])\n    plt.xlabel(x)\n    plt.ylabel(y)\n    plt.title('{} vs {}'.format(x,y))\n    plt.show()\n\nscatter_plot(master_df,'Total_Expense','KMs Reading')","execution_count":null,"outputs":[]},{"metadata":{"id":"MBOnrQh2N3ap","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":448},"outputId":"91d94170-c413-4861-f9ee-1450d48edf7e","trusted":true},"cell_type":"code","source":"def plot_groupby(df,grpby_col, col):\n    gp=df.groupby(grpby_col)[col].sum()\n    gp=100*gp/sum(gp)\n    gp=gp[gp>1]\n    gp.sort_values().plot(kind='barh')\n    plt.style.use('fivethirtyeight')\n    plt.title('{}wise Total {} percentage'.format(grpby_col, col))\n    plt.xlabel('Percentage')\n    plt.tight_layout()\n\nplot_groupby(master_df,'Make','Total_Expense')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_groupby(master_df,'State','Total_Expense')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Problem Statement-2**: Identify the type of order each state receives and present it\nas an interactive visualization."},{"metadata":{"id":"nkFTbqLNgztD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":505},"outputId":"f8849ab6-03fd-413d-c84c-8ceb62dd071d","trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(15,7))\nplt.style.use('fivethirtyeight')\ninvoice_df.groupby('Order Type')['Total Amt Wtd Tax.'].count().plot(kind='pie',ax=ax[0])\ninvoice_df.groupby('Order Type')['Total Amt Wtd Tax.'].sum().plot(kind='pie',ax=ax[1])\nplt.tight_layout()\nplt.title('Countwise And Earningwise Order type distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lifetime customer Value\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lifetime customer Value\n\n## customer expenditures per visit\n\ns = (sum(invoice_df.groupby(['Customer No.'])[\"Total Amt Wtd Tax.\"].sum()))/502774\n\n### number of visits per month (the “purchase cycle”)\n\nfrom dateutil.relativedelta import relativedelta\n\nfrom datetime import *\ninvoice_df['Invoice Date']=pd.to_datetime(invoice_df['Invoice Date'])\ninvoice_df['year']=invoice_df['Invoice Date'].dt.year\ninvoice_df['month']=invoice_df['Invoice Date'].dt.month\n\nc = (invoice_df.groupby(['Customer No.'])[\"month\"].count()).mode()\n\nt = ((invoice_df.groupby(['Customer No.'])[\"Invoice Date\"].max() - invoice_df.groupby(['Customer No.'])[\"Invoice Date\"].min())/np.timedelta64(1,'M')).mean()\n\na = s * c\n\nSLTV = (12 * a) * t\n\nCLTV = t*12*s*c\nCLTV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\ndef Knumber(df):\n      dist=[]\n      # Iterate from 1-9\n      for i in range(1,10):\n            # Initialize KMeans algorithm\n            km=KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n            # Fit on data\n            km.fit(df)\n            # Append WCSS to list storing WCSS\n            dist.append(km.inertia_)\n      # Initialize figure\n      fig=plt.figure( figsize=[10,8])\n      # Line plot # clusters on X-axis and WCSS on Y-axis \n      plt.plot(range(1,10),dist)\n      plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=invoice_df[['KMs Reading','Total Amt Wtd Tax.']]\nKnumber(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster=KMeans(n_clusters=4,init='k-means++',max_iter=300,n_init=10,random_state=0)\n# create 'cluster' column\ndf['cluster']=cluster.fit_predict(df)\ndf.plot.scatter('KMs Reading','Total Amt Wtd Tax.', c='cluster', cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=invoice_df[['Parts Total','Total Amt Wtd Tax.']]\nKnumber(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster=KMeans(n_clusters=4,init='k-means++',max_iter=300,n_init=10,random_state=0)\n# create 'cluster' column\ndf1['cluster']=cluster.fit_predict(df)\ndf1.plot.scatter('Parts Total','Total Amt Wtd Tax.', c='cluster', cmap='viridis')","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"MFC_Capstone.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}