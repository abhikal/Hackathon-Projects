{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFC_Capstone.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripidhoble/Hackathon-Projects/blob/master/MFC_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHc4hn2bUEco",
        "colab_type": "code",
        "outputId": "3032e9c1-f13a-449d-819d-39d5f7c77aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "pip install fuzzywuzzy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQqqS__ljOuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34HWyzcGjqpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POjDy7jbxQqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import important libraries\n",
        "from fuzzywuzzy import process\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhtkA45ajcHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"drive/My Drive/data/\"\n",
        "\n",
        "customer_df = pd.read_csv(path + 'customer.csv')\n",
        "invoice_df = pd.read_csv(path + 'invoice.csv')\n",
        "jtd_df = pd.read_csv(path + 'jtd.csv')\n",
        "plant_df = pd.read_csv(path + 'plant.csv')\n",
        "vehicles_df = pd.read_csv(path + 'vehicles.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2zIxRzAkpQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. drop unwanted columns from all dataframes\n",
        "# 2. lowercase all the categorical columns\n",
        "\n",
        "def drop_col(dataset, col_to_drop):\n",
        "    dataset.drop(col_to_drop, axis=1, inplace=True)\n",
        "    return dataset\n",
        "\n",
        "def lowercase(dataset):\n",
        "    categorical_col = dataset.select_dtypes(exclude=['number']).columns\n",
        "    for col in categorical_col:\n",
        "        dataset[col] = dataset[col].map(lambda x: x if type(x)!=str else x.lower())\n",
        "    return dataset\n",
        "\n",
        "invoice_columns_to_drop = ['Unnamed: 0', 'Amt Rcvd From Custom', 'Amt Rcvd From Ins Co','Area / Locality',\n",
        "                           'CGST(14%)', 'CGST(2.5%)', 'CGST(6%)', 'CGST(9%)',\n",
        "                           'IGST(12%)', 'IGST(18%)', 'IGST(28%)', 'IGST(5%)', 'Insurance Company',\n",
        "                           'Outstanding Amt', 'SGST/UGST(14%)', 'SGST/UGST(2.5%)', 'SGST/UGST(6%)', 'SGST/UGST(9%)',\n",
        "                           'Service Advisor Name', 'TDS amount', 'Total CGST', 'Total GST', 'Total IGST',\n",
        "                           'Total SGST/UGST','Plant Name1','Recovrbl Exp']\n",
        "customer_columns_to_drop = ['Unnamed: 0','Death date']\n",
        "plant_columns_to_drop = ['Unnamed: 0','Name 1','Factory calendar','Valuation Area',\n",
        "                         'Customer no. - plant','PO Box','Postal Code','Name 2',\n",
        "                         'Vendor number plant','House number and street']\n",
        "jtd_columns_to_drop = ['Unnamed: 0']\n",
        "vehicles_columns_to_drop = ['Unnamed: 0','Product GUID']\n",
        "\n",
        "dataframes = [invoice_df, customer_df, plant_df, jtd_df, vehicles_df]\n",
        "dataframe_columns_to_drop = [invoice_columns_to_drop, customer_columns_to_drop, plant_columns_to_drop, jtd_columns_to_drop, vehicles_columns_to_drop]\n",
        "\n",
        "for i in range(len(dataframes)):\n",
        "  dataframes[i] = drop_col(dataframes[i],dataframe_columns_to_drop[i])\n",
        "  dataframes[i] = lowercase(dataframes[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVeGROVWuCIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Preprocessing for dataset merge operation\n",
        "\n",
        "# 1. Remove leading zeros from 'Customer No.' column\n",
        "def remove_leading_zeros(dataset,cols):\n",
        "    for col in cols:\n",
        "      dataset[col] = dataset[col].astype(str).apply(lambda x: x.lstrip(\"0\"))\n",
        "    return dataset\n",
        "invoice_df  = remove_leading_zeros(invoice_df,['Customer No.'])\n",
        "customer_df = remove_leading_zeros(customer_df,['Customer No.'])\n",
        "\n",
        "\n",
        "# 2. Rename columns to use them as key column for merge operation\n",
        "def rename_columns(dataset, rename_cols_dict):\n",
        "    dataset.rename(columns=rename_cols_dict, inplace=True)\n",
        "    return dataset\n",
        "dict_invoice_df = {'District':'State'}\n",
        "dict_vehicles_df = {'Vehicle Model':'Make', 'License Plate Number':'Regn No'}\n",
        "\n",
        "invoice_df  = rename_columns(invoice_df, dict_invoice_df)\n",
        "vehicles_df = rename_columns(vehicles_df, dict_vehicles_df)\n",
        "\n",
        "\n",
        "# 3. Replace values in key columns for merge operation\n",
        "def replacement(dataset, col, dict_replacement, regex=False):\n",
        "    dataset[col] = dataset[col].replace(dict_replacement, regex=regex )\n",
        "    return dataset\n",
        "make_replacements = {\n",
        "                    'mahindra &  mahindra': 'mahindra',\n",
        "                    'tata motors': 'tata',\n",
        "                    'maruti suzuki': 'maruti',\n",
        "                    'mercedes benz': 'mercedes-benz',\n",
        "                    'porche': 'porsche',\n",
        "                    'land rover' : 'rover',\n",
        "                    'mitsubishi motors':'mitsubishi motor',\n",
        "                    'premier\\xa0automobiles': 'premierauto'\n",
        "                    }\n",
        "pattern_replacement = {'z_':''}\n",
        "vehicles_df = replacement(vehicles_df, 'Make', pattern_replacement, regex=True)\n",
        "vehicles_df = replacement(vehicles_df, 'Make', make_replacements)\n",
        "invoice_df  = replacement(invoice_df, 'Make', make_replacements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCInjJg5KlgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# invoice_df['Invoice Date']=pd.to_datetime(invoice_df['Invoice Date'])\n",
        "\n",
        "# invoice_df['year']=invoice_df['Invoice Date'].dt.year\n",
        "# invoice_df['month']=invoice_df['Invoice Date'].dt.month\n",
        "\n",
        "# # use unstack()\n",
        "# list=['maharashtra', 'tamil Nadu', 'madhya pradesh','andhra pradesh', 'uttar pradesh', 'rajasthan']\n",
        "# list2=['Karnataka','West Bengal', 'Uttarakhand', 'Odisha', 'Telangana', 'Bihar', 'Punjab', 'Haryana', 'Gujarat' ]\n",
        "# invoice_df['state']=invoice_df['State']\n",
        "# invoice_df['state']=invoice_df['state'].apply(lambda x:'no' if x not in list else 'yes')\n",
        "# state_df=invoice_df[invoice_df['state'] == 'yes']\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(15,7))\n",
        "# state_df.groupby(['year','State'])['Total Amt Wtd Tax.'].sum().unstack().plot(ax=ax,marker='o')\n",
        "# plt.title('Yearwise total amt spent in top states')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYCqD9ttNkPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bwnf_Q2LvmGg",
        "colab": {}
      },
      "source": [
        "# Merge dataframes based on key\n",
        "def merge_df(left_df, right_df, key):\n",
        "    merge_df = pd.merge(left=left_df, right=right_df, how='left', on=key)\n",
        "    return merge_df\n",
        "\n",
        "invoice_customer_df = merge_df(left_df=invoice_df, right_df=customer_df,key=['Customer No.'])\n",
        "invoice_customer_plant_df = merge_df(left_df=invoice_customer_df, right_df=plant_df,key=['Plant','State'])\n",
        "invoice_customer_plant_vehicles_df = merge_df(left_df=invoice_customer_plant_df, right_df=vehicles_df,key=['Regn No','Make'])\n",
        "\n",
        "master_df = invoice_customer_plant_vehicles_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01UPBWu0KzgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"invoice_df shape: \",invoice_df.shape)\n",
        "print(\"customer_df shape: \",customer_df.shape)\n",
        "print(\"invoice_customer_df shape: \",invoice_customer_df.shape)\n",
        "print(\"plant_df shape: \",plant_df.shape)\n",
        "print(\"invoice_customer_plant_df shape: \",invoice_customer_plant_df.shape)\n",
        "print(\"vehicles_df shape: \",vehicles_df.shape)\n",
        "print(\"invoice_customer_plant_vehicles_df shape: \",invoice_customer_plant_vehicles_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BDjlDr4BmMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill missing values of 'CITY' column \n",
        "master_df['CITY'].fillna(master_df['City'], inplace = True)\n",
        "\n",
        "#remove dulicate column 'City'\n",
        "master_df = drop_col(dataset=master_df, col_to_drop=['City'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ebfqCjDyxUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to identify the number of missing values in every feature\n",
        "def missing_datas(dataset):\n",
        "    total = dataset.isnull().sum().sort_values(ascending=False)\n",
        "    percent = ((dataset.isnull().sum())*100/dataset.isnull().count()).sort_values(ascending=False)\n",
        "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    return missing_data\n",
        "    \n",
        "missing_data_master_df = missing_datas(master_df)\n",
        "print(\"missing data for 'master_df': \")\n",
        "print(missing_data_master_df[missing_data_master_df['Percent']>0.00])\n",
        "\n",
        "missing_data_jtd_df = missing_datas(jtd_df)\n",
        "print(\"missing data for 'jtd_df': \")\n",
        "print(missing_data_jtd_df[missing_data_jtd_df['Percent']>0.00])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3XDnJTC0zmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to drop missing values\n",
        "def drop_missing(dataset, missing, min_threshold, max_threshold):\n",
        "    dataset = dataset.drop((missing[missing['Percent'] > max_threshold]).index,axis= 1)\n",
        "    dataset = dataset.dropna(axis=0, subset=(missing[missing['Percent'] < min_threshold]).index)\n",
        "    return dataset \n",
        "\n",
        "master_df  = drop_missing(master_df,missing_data_master_df,2,40)\n",
        "jtd_df     = drop_missing(jtd_df,missing_data_jtd_df,2,40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPjHYn-Qb1X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#recheck the missing values\n",
        "new_missing_data = missing_datas(master_df)\n",
        "print(\"missing data for 'master_df'\")\n",
        "print(new_missing_data[new_missing_data['Percent']>0.00])\n",
        "\n",
        "new_missing_data = missing_datas(jtd_df)\n",
        "print(\"missing data for 'jtd_df'\")\n",
        "print(new_missing_data[new_missing_data['Percent']>0.00])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWLLSDnKNpiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fill missing values with mode\n",
        "def Fill_Missing_Values(dataset, cols):\n",
        "    for col in cols:\n",
        "      dataset[col].fillna(dataset[col].dropna().mode()[0], inplace = True)\n",
        "    return dataset\n",
        "  \n",
        "master_df = Fill_Missing_Values(dataset=master_df,cols=['Sales organization','Title','Fuel Type'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqzSDGdOoxx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combine Date & Time columns\n",
        "def to_datetime(dataset, datetime_cols):\n",
        "    for datetime in datetime_cols:\n",
        "      dataset[datetime[0] + '-' + datetime[1]] = pd.to_datetime(dataset[datetime[0]]+ ' ' + dataset[datetime[1]])\n",
        "    return dataset\n",
        "datetime_cols = ['Invoice Date','Invoice Time','JobCard Date','JobCard Time']\n",
        "master_df = to_datetime(master_df, [['Invoice Date','Invoice Time'],['JobCard Date','JobCard Time']])\n",
        "\n",
        "\n",
        "#split datetime column\n",
        "master_df['Year']  = master_df['Invoice Date-Invoice Time'].dt.year\n",
        "master_df['Month'] = master_df['Invoice Date-Invoice Time'].dt.month\n",
        "\n",
        "\n",
        "# add job duration column\n",
        "def job_completion_time(dataset, start_datetime, end_datetime):\n",
        "    dataset['Job_duration(in days)'] = (dataset[start_datetime] - dataset[end_datetime]) / np.timedelta64(1,'D')\n",
        "    return dataset\n",
        "master_df = job_completion_time(master_df, 'Invoice Date-Invoice Time', 'JobCard Date-JobCard Time')\n",
        "\n",
        "\n",
        "# add total all costs to get 'Total Expenses'\n",
        "def sum_cols(dataset, cols_to_sum, result_col):\n",
        "  dataset[result_col] = 0\n",
        "  for col in cols_to_sum:\n",
        "      dataset[result_col] = dataset[result_col] + dataset[col]\n",
        "  return dataset\n",
        "cost_cols     = ['Misc Total','OSL Total','Parts Total','Total Amt Wtd Tax.']\n",
        "master_df =  sum_cols(master_df, cost_cols, 'Total_Expense')\n",
        "\n",
        "\n",
        "#remove dulicate column Date-Time columns\n",
        "master_df = drop_col(master_df, datetime_cols)\n",
        "master_df = drop_col(master_df, cost_cols)\n",
        "\n",
        "# drop unique value columns\n",
        "unique_cols = ['User ID','Regn No','Pin code','Customer No.','Invoice No','Job Card No']\n",
        "master_df = drop_col(master_df, unique_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8dlXs5-Ttvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map column description\n",
        "def map_description(dataset,col, map_dict):\n",
        "    dataset[col] = dataset[col].astype(str).map(map_dict)\n",
        "    return dataset\n",
        "\n",
        "data_origin_dict = { 'z001':'Camp-Outdoor','z002':'Camp-Workshop','z003':'Emailers',\n",
        "                     'z004':'Fleet','z005':'Ref-Customer','z006':'Ref-Employee',\n",
        "                     'z007':'Used Car Dealer','z008':'Just Dial/Other',\n",
        "                     'z009':'Snapdeal/Web','z010':'Company website',\n",
        "                     'z011':'Float activity','z012':'Petrol pump',\n",
        "                     'z013':'Hoardings/ADVT','z014':'Insurance Co',\n",
        "                     'z015':'Television AD','z016':'Newspaper AD',\n",
        "                     'z017':'Newsppr leaflet','z018':'Sales Activity',\n",
        "                     'z019':'Spotted outlet','z020':'M & M Employee',\n",
        "                     'z021':'Outdoor Activty','z022':'Radio'\n",
        "                  }\n",
        "\n",
        "partner_type_dict = {'1.0':'Retail','2.0':'Corporate','3.0':'Fleet',\n",
        "                     '4.0':'Employee','9001.0':'Insurance Company',\n",
        "                     '9002.0':'Surveyor','9003.0':'Contact Person'\n",
        "                    }\n",
        "\n",
        "master_df = map_description(master_df,'Data Origin', data_origin_dict)\n",
        "master_df = map_description(master_df,'Partner Type', partner_type_dict)\n",
        "\n",
        "# change columns dtype\n",
        "\n",
        "def modify_col_type(dataset, col, dtype):\n",
        "    dataset[col] = dataset[col].astype(dtype)\n",
        "    return dataset\n",
        "\n",
        "master_df = modify_col_type(master_df, 'Fuel Type', int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irj6rlFfjsto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to identify numeric features\n",
        "def numeric_features(dataset):\n",
        "    numeric_col = dataset.select_dtypes(include=['number']).columns\n",
        "    return numeric_col\n",
        "\n",
        "numeric_columns_master_df = numeric_features(master_df)\n",
        "print(\"Numeric Features for master_df:\")\n",
        "print(numeric_columns_master_df)\n",
        "\n",
        "numeric_columns_jtd_df = numeric_features(jtd_df)\n",
        "print(\"Numeric Features for jtd_df:\")\n",
        "print(numeric_columns_jtd_df)\n",
        "\n",
        "print(\"====\"*30)\n",
        "\n",
        "# Function to identify categorical features\n",
        "def categorical_features(dataset):\n",
        "    categorical_col = dataset.select_dtypes(exclude=['number']).columns\n",
        "    return categorical_col\n",
        "\n",
        "categorical_columns_master_df = categorical_features(master_df)\n",
        "print(\"Categorical Features for master_df:\")\n",
        "print(categorical_columns_master_df)\n",
        "\n",
        "categorical_columns_jtd_df = categorical_features(jtd_df)\n",
        "print(\"categorical Features for jtd_df:\")\n",
        "print(categorical_columns_jtd_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdfF0dCjX2ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_unique_values(dataset, categirical_cols):\n",
        "    print(\"Unique values: \")  \n",
        "    for col in categirical_cols:\n",
        "          print(\"{} : {}\".format(col, dataset[col].unique()))\n",
        "    return None\n",
        "  \n",
        "# display_unique_values(master_df, categorical_columns_master_df)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_N_I3Ye381D",
        "colab_type": "text"
      },
      "source": [
        "# **Univariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUhyAM7vGK7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_CountPlot(dataset,col,title=None):\n",
        "    filtered_df = dataset[col].value_counts()\n",
        "    filtered_df=filtered_df.reset_index()\n",
        "    filtered_df[col] = (filtered_df[col]/sum(filtered_df[col]))*100\n",
        "    filtered_df = filtered_df.sort_values(col)\n",
        "    filtered_df = filtered_df[filtered_df[col]>1]\n",
        "    plt.barh(filtered_df['index'],filtered_df[col])\n",
        "    \n",
        "    plt.style.use('seaborn')\n",
        "    if(title==None):\n",
        "        plt.title('Count plot for {}'.format(col))\n",
        "    plt.xlabel('Percentage')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  \n",
        "# plot_vc(master_df,'Data Origin','how customers know abt MFCS')\n",
        "# plot_vc(master_df,'Make','Make wise distribution')\n",
        "plot_CountPlot(master_df,'State')\n",
        "# plot_vc(master_df[master_df['State'] == 'maharashtra'],'CITY','Citywise distribution in maharashtra')\n",
        "# plot_vc(master_df[master_df['State'] == 'tamil nadu'],'CITY','Citywise distribution in TN')\n",
        "# plot_vc(master_df,'Order Type','Order type distribution')\n",
        "# plot_vc(master_df[master_df['State'] == 'maharashtra'],'Plant Name1','plant wise distribution in maharashtra')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9jtMHPoJ6mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_values(dataset,col):\n",
        "    filtered_df = dataset[col].value_counts()\n",
        "    filtered_df=filtered_df.reset_index()\n",
        "    filtered_df[col] = (filtered_df[col]/sum(filtered_df[col]))*100\n",
        "    filtered_df = filtered_df.sort_values(col)\n",
        "    filtered_df = filtered_df[filtered_df[col]>1]\n",
        "    top_values  = filtered_df['index'].tolist()\n",
        "    top_values_df = dataset[dataset[col].isin(top_values)]\n",
        "    return top_values_df, top_values\n",
        "\n",
        "def plot_TimeSeries(dataset, time_col, cat_col, num_col):\n",
        "    fig, ax = plt.subplots(figsize=(15,7))\n",
        "    plt.title(\"'{}'wise '{}' in top '{}'\".format(time_col, num_col, cat_col))\n",
        "    dataset.groupby([time_col,cat_col])[num_col].sum().unstack().plot(ax=ax,marker='o')\n",
        "    \n",
        "top_state_df, top_state = get_top_values(master_df, 'State')\n",
        "plot_TimeSeries(top_state_df,'Year','State','Total_Expense')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17M3xM8EZNzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"columns from invoice_df: \",set(master_df.columns) & set(invoice_df.columns))\n",
        "print(\"columns from customer_df: \",set(master_df.columns) & set(customer_df.columns))\n",
        "print(\"columns from plant_df: \",set(master_df.columns) & set(plant_df.columns))\n",
        "print(\"columns from vehicles_df: \",set(master_df.columns) & set(vehicles_df.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wqg3wzc7Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scatter_plot(df,x,y):\n",
        "  plt.style.use('seaborn')\n",
        "  plt.scatter(df[x],df[y])\n",
        "  #cbar=plt.colorbar()\n",
        "  #cbar.set_label('Price variation')\n",
        "  plt.xlabel(x)\n",
        "  plt.ylabel(y)\n",
        "  plt.title('{} vs {}'.format(x,y))\n",
        "  plt.show()\n",
        "\n",
        "scatter_plot(master_df,'Total_Expense','KMs Reading')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBOnrQh2N3ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_groupby(df,grpby_col, col):\n",
        "  gp=df.groupby(grpby_col)[col].sum()\n",
        "  gp=100*gp/sum(gp)\n",
        "  gp=gp[gp>1]\n",
        "  print(gp.index)\n",
        "  gp.sort_values().plot(kind='barh')\n",
        "  plt.style.use('fivethirtyeight')\n",
        "  plt.title('{}wise Total {} percentage'.format(grpby_col, col))\n",
        "  plt.xlabel('Percentage')\n",
        "  plt.tight_layout()\n",
        "\n",
        "plot_groupby(master_df,'Make','Total_Expense')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkFTbqLNgztD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
        "plt.style.use('fivethirtyeight')\n",
        "invoice_df.groupby('Order Type')['Total Amt Wtd Tax.'].count().plot(kind='pie',ax=ax[0])\n",
        "plt.title('Countwise And Earningwise Order type distribution',loc='left')\n",
        "invoice_df.groupby('Order Type')['Total Amt Wtd Tax.'].sum().plot(kind='pie',ax=ax[1])\n",
        "plt.tight_layout()\n",
        "#plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kYJr9Bw7DULV",
        "colab": {}
      },
      "source": [
        "# import sys\n",
        "digits = []\n",
        "correct_string = []\n",
        "corrected_string = []\n",
        "error_string = []\n",
        "punctuation_string = []\n",
        "top_city_df, top_cities = get_top_values(master_df, 'CITY')\n",
        "top_cities.remove('nasik')\n",
        "\n",
        "def spellcorrect(string):\n",
        "      if (string.isdigit()):\n",
        "              digits.append(string)\n",
        "      elif(bool(re.match('[a-zA-Z]', string))):\n",
        "          best_guess = process.extractOne(string, top_cities)\n",
        "          if(len(string.split())<=2):\n",
        "              if(best_guess[1]>=80):\n",
        "                    corrected_string.append(string)\n",
        "                    string = best_guess[0]\n",
        "          elif(len(string.split())>2):\n",
        "              if(best_guess[1]>=70):\n",
        "    #                 print(string,best_guess[0])\n",
        "                    corrected_string.append(string)\n",
        "                    string = best_guess[0]\n",
        "              else:\n",
        "                  error_string.append(string)\n",
        "          else:\n",
        "              correct_string.append(string)\n",
        "      else:\n",
        "            punctuation_string.append(string)\n",
        "      return string\n",
        "          \n",
        "def typo_check(dataset,col): \n",
        "    dataset[col] = dataset[col].apply(spellcorrect)\n",
        "    return dataset\n",
        "  \n",
        "master_df = typo_check(master_df, 'CITY')\n",
        "\n",
        "# not_corrected.sort()\n",
        "# digits.sort()\n",
        "# corrected_string.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJW2CY4O-kcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user_input = \"bengalore\"\n",
        "# best_guess = process.extractOne(user_input, top_cities)\n",
        "# if(best_guess[1]>67):\n",
        "#     print(f\"The best match for '{user_input}' is '{best_guess[0]}' which is a {best_guess[1]}% match.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOiL2pPk0b0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = sorted(set(digits))\n",
        "correct_string = sorted(set(correct_string))\n",
        "corrected_string = sorted(set(corrected_string))\n",
        "error_string = sorted(set(error_string))\n",
        "punctuation_string = sorted(set(punctuation_string))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJh3IxqVf1RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(digits))\n",
        "print(len(correct_string))\n",
        "print(len(corrected_string))\n",
        "print(len(error_string))\n",
        "print(len(punctuation_string))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZBZJKwgwPvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "master_df.to_csv('master_df.csv', index=False)\n",
        "files.download('master_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsPaT_ewBkhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}